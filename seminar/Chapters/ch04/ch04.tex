\chapter{IMPLEMENTATION}
The implementation include in this seminar report is carried out in the python programming language. Following python libraries are used for the implementation purpose.
\begin{itemize}
  \item {\textbf{Pandas:} pandas is one of the most important libraries of the python programming language, it is used to import the dataset and to obtain the statistical description of the dataset.}
  \item {\textbf{Matplotlib:} This library has been used for plotting graphs. The functions used from this library are as follows: plot(); plot various visualization, show(); to visualize the plots, line(); plot a line graph.}
  \item {\textbf{Sklearn:} This library has been used for splitting the train and test data.}
  \item{\textbf{TensorFlow:} It can be used across a range of task but has a particular focus on training and inference of deep neural network. In this seminar report we use 2.5.3 version of TensorFlow.}
  \item{\textbf{Keras:} It provides a python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.
  }
\end{itemize}





\section{Data Collection}
Dataset used in this seminar report is collected by performing web scraping process. For this, beautiful soup library is used which is freely available in python programming language. The code snippets for the data collection is depicted in the appendix [A]. 
\section{Preprocessing}
After the data collection process has been completed, the preprocessing task is inaugurated. This process plays a vital role in feature extraction as well as in the machine learning algorithm. It includes different activities such as removing secondary languages, special characters.
\section{Feature Extraction}
Processed data is not directly trained into the machine learning model. In this report, both context dependent and independent techniques are used for converting the text data into the numeric form. Before generating the vector of the data, a news corpus is generated by splitting total word present in the news to a single list and then implement the following techniques.
\subsection{Word2Vec}
The Word2Vec word embedding module is loaded by using genism library available in the python programming language. Additionally, this model only supports the tokenized words so, news is tokenized before passing into it. All in all, different hyperparameters such as size, window size, minimum counts etc., need to be pass for the training process. The code snippets for training this model is depicted in the appendix [B]. 
\subsection{ELMo}
The ELMO model is introduced by Google. It is a pretrained model which is loaded by the help of TensorFlow hub library. Then the preprocessed data is passed for training. Moreover, because of inefficient of computational resources such as Ram, data is divided by taking a window size 20. This model works based on LSTM, so it takes a little bit more time for training as compared to others module. The code snippets for training this model is depicted in the appendix [C]. 
\section{Model Develop and Train}
In this seminar report, SVM and Random forest machine learning algorithms are used for the analysis purpose. These models are loaded from the sklearn library available in python programming language. Additionally, sigmoid kernel is used for classifying the data in SVM. The preprocessed dataset is splitted into train and test in 8:2 ratio for training the model.
\section{System Specification}
The experiment is carried out in the machine with following specifications:\
\begin{itemize}
  \item{\textbf{Processor}: Apple Chip M1}
    \item{\textbf{Ram}: 8 GB}
      \item{\textbf{System Type}: MacOS Monterey}
        \item{\textbf{No of Cores}: 8}
          \item{\textbf{No of Threads}: 4}
\end{itemize}